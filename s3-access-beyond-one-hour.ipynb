{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ebe7887",
   "metadata": {},
   "source": [
    "# Demonstration of S3 in-region access to Earthdata Cloud data using auto-refreshed STS keys\n",
    "In this notebook we will demonstrate how you can find cloud-hosted data within EDC and access that data using AWS' S3 API for in-region compute without having to manually refresh keys each hour.\n",
    "\n",
    "Note: this technique relies on an un-documented feature of the BOTO-3 python SDK. Reliance on this functionality bears a risk.\n",
    "\n",
    "EDC data is hosted in us-west-2. In order to run this notebook you need the following,\n",
    "- An EDL account (you can gain one at urs.earthdata.nasa.gov)\n",
    "- A notebook server running in us-west-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d9576fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request, parse\n",
    "from http.cookiejar import CookieJar\n",
    "import getpass\n",
    "import netrc\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5867ecfb",
   "metadata": {},
   "source": [
    "## Registration and authentication\n",
    "\n",
    "In order to access EDC data you need to register with Earthdata Login (EDL) and obtain EDL credentials for your data access.\n",
    "\n",
    "This function below will allow Python scripts to log into the Earthdata Login application programmatically. To avoid being prompted for credentials every time you run and also allow clients such as curl to log in, you can add the following to a .netrc (_netrc on Windows) file in your home directory:\n",
    "\n",
    "machine urs.earthdata.nasa.gov\n",
    "    login <your username>\n",
    "    password <your password>\n",
    "Make sure that this file is only readable by the current user or you will receive an error stating \"netrc access too permissive.\"\n",
    "\n",
    "$ chmod 0600 ~/.netrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa04a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_earthdata_login_auth(endpoint):\n",
    "    \"\"\"\n",
    "    Set up the request library so that it authenticates against the given Earthdata Login\n",
    "    endpoint and is able to track cookies between requests.  This looks in the .netrc file \n",
    "    first and if no credentials are found, it prompts for them.\n",
    "\n",
    "    Valid endpoints include:\n",
    "        uat.urs.earthdata.nasa.gov - Earthdata Login UAT\n",
    "        urs.earthdata.nasa.gov - Earthdata Login production\n",
    "    \"\"\"\n",
    "    try:\n",
    "        username, _, password = netrc.netrc().authenticators(endpoint)\n",
    "    except (FileNotFoundError, TypeError):\n",
    "        # FileNotFound = There's no .netrc file\n",
    "        # TypeError = The endpoint isn't in the netrc file, causing the above to try unpacking None\n",
    "        print('Please provide your Earthdata Login credentials to allow data access')\n",
    "        print('Your credentials will only be passed to %s and will not be exposed in Jupyter' % (endpoint))\n",
    "        username = input('Username:')\n",
    "        password = getpass.getpass()\n",
    "\n",
    "    manager = request.HTTPPasswordMgrWithDefaultRealm()\n",
    "    manager.add_password(None, endpoint, username, password)\n",
    "    auth = request.HTTPBasicAuthHandler(manager)\n",
    "\n",
    "    jar = CookieJar()\n",
    "    processor = request.HTTPCookieProcessor(jar)\n",
    "    opener = request.build_opener(auth, processor)\n",
    "    request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29611f0f",
   "metadata": {},
   "source": [
    "Let's set up our EDL authentication against the producton environment at urs.earthdata.nasa.gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2af21c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_earthdata_login_auth('urs.earthdata.nasa.gov')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bdbad5",
   "metadata": {},
   "source": [
    "## Data discovery via the Common Metadata Repository (CMR)\n",
    "### Step 1: Collection/Dataset discovery.\n",
    "We can search for collections of interest in our cloud provider POCLOUD using CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42205f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://cmr.earthdata.nasa.gov/search/collections.json', params={'provider': 'POCLOUD'})\n",
    "results = json.loads(response.content)\n",
    "\n",
    "concept_id = results[\"feed\"][\"entry\"][0][\"id\"]\n",
    "print(\"Unique identifier of collection: \" + concept_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab03c1ab",
   "metadata": {},
   "source": [
    "Note that this collection metadata describes several things you need to know about accessing EDC data via S3\n",
    "In order to use EDC S3 we need to know the following\n",
    "- the region the data is housed in\n",
    "- how to obtain AWS STS credentials (ie. the STS credentials endpoint and documentation\n",
    "EDC needs to metric each data access in terms of the user performing the access. This is done by linking your EDL user name to an STS role. The STS credential endpoint does that by asking for your EDL credentials and returning temporay STS credentials that you can use to set up an AWS S3 client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://cmr.earthdata.nasa.gov/search/concepts/' + concept_id + '.umm-json')\n",
    "results = json.loads(response.content)\n",
    "aws_region = results[\"DirectDistributionInformation\"][\"Region\"]\n",
    "print('AWS region: ' + aws_region)\n",
    "sts_endpoint = results[\"DirectDistributionInformation\"][\"S3CredentialsAPIEndpoint\"]\n",
    "print('AWS STS endpoint: ' + sts_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f9b9f9",
   "metadata": {},
   "source": [
    "### Step 2: Granule/file discovery.\n",
    "Using the unique identifier for the first collection returned, we can search for granules and obtain one or more S3 urls locating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be47157",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://cmr.earthdata.nasa.gov/search/granules.json', params={'concept_id': concept_id})\n",
    "results = json.loads(response.content)\n",
    "\n",
    "links = results[\"feed\"][\"entry\"][0][\"links\"]\n",
    "for link in links:\n",
    "    if link['rel'] == \"http://esipfed.org/ns/fedsearch/1.1/s3#\":\n",
    "        url = link['href']\n",
    "        break;\n",
    "print(\"S3 URL for data: \" + url)\n",
    "o = urlparse(url, allow_fragments=False)\n",
    "\n",
    "bucket = o.netloc\n",
    "\n",
    "key = o.path.lstrip('/')\n",
    "print(\"S3 bucket: \" + bucket)\n",
    "print(\"S3 key: \" + key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b230868",
   "metadata": {},
   "source": [
    "## Accessing data\n",
    "Now we have found the location of the data, we need to leverage the S3 API to access it. \n",
    "### Step 1: Obtain AWS STS credentials.\n",
    "EDC requires AWS STS credentials for data access the STS endpoint allows us to use our EDL credentials to obtain them.\n",
    "Our EDL credentials are in our https session so the STS endpoint will recognize that and use them to return us STS credentials.\n",
    "\n",
    "Here we use an undocumented function in the botocore library that allows you to auto-refresh your credentials. This will allow you to maintain your session for more than the 1 hour limit.\n",
    "\n",
    "See https://github.com/boto/botocore/blob/e8155d6005a878b86bfdcd2823b41f7e2d6cde08/botocore/credentials.py#L444\n",
    "\n",
    "This feature will automatically refresh your STS tokens prior to their expiration without the need for intervention. You can 'set it and forget it'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3818f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore, datetime\n",
    "\n",
    "def refresh_external_credentials():\n",
    "    response = requests.get(sts_endpoint)\n",
    "    creds = json.loads(response.content)\n",
    "    return {\n",
    "        \"access_key\": creds.get('accessKeyId'),\n",
    "        \"secret_key\": creds.get('secretAccessKey'),\n",
    "        \"token\": creds.get('sessionToken'),\n",
    "        \"expiry_time\": creds.get('expiration')\n",
    "    }\n",
    "\n",
    "credentials = botocore.credentials.RefreshableCredentials.create_from_metadata(\n",
    "    metadata=refresh_external_credentials(),\n",
    "    refresh_using=refresh_external_credentials,\n",
    "    method=\"sts-assume-role\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20debf4",
   "metadata": {},
   "source": [
    "### Step 2: Accessing the data via the AWS S3 API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8324197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from botocore.session import get_session\n",
    "\n",
    "session = get_session()\n",
    "session._credentials = credentials\n",
    "session.set_config_variable(\"region\", 'us-west-2')\n",
    "autorefresh_session = boto3.session.Session(botocore_session=session)\n",
    "        \n",
    "client = autorefresh_session.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b39bd",
   "metadata": {},
   "source": [
    "The code below performs an S3 GetObject operation every minute, for two hours. Without auto-refresh of credentials, this would fail after one hour. With auto-refresh it will succeed to compeletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c20cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:34:57.536733\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:35:57.744635\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:36:57.956452\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:37:58.124399\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:38:58.268039\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:39:58.435814\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:40:58.566645\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:41:58.688394\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:42:58.777260\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:43:58.877006\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:44:58.985053\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:45:59.108398\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:46:59.219704\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:47:59.361468\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:48:59.478142\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:49:59.596410\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:50:59.684433\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:51:59.804452\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:52:59.918767\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:54:00.036433\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:55:00.188438\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:56:00.308977\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:57:00.424416\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:58:00.485886\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 13:59:00.566873\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:00:00.657911\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:01:00.779494\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:02:00.964399\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:03:01.088409\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:04:01.226981\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:05:01.358163\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:06:01.504427\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:07:01.632491\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:08:01.810331\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:09:01.943389\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:10:02.080396\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:11:02.667532\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:12:02.814128\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:13:02.929409\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:14:03.046911\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:15:03.166969\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:16:03.327732\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:17:03.448890\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:18:03.542691\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:19:03.656394\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:20:03.767594\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:21:09.564434\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:22:09.687246\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:23:09.808238\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:24:09.940398\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:25:10.106727\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:26:10.242279\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:27:10.390662\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:28:10.511671\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:29:10.648399\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:30:10.764412\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:31:10.896405\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:32:11.005568\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:33:11.132396\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:34:11.263832\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:35:11.368164\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:36:11.492387\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:37:11.606760\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:38:11.736408\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:39:11.858239\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:40:11.992392\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:41:12.067799\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:42:12.186677\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:43:12.296416\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:44:12.419333\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:45:12.556418\n",
      "You just accessed 5289869 bytes of data in-region via the AWS S3 API at \n",
      "2022-10-19 14:46:12.693914\n"
     ]
    }
   ],
   "source": [
    "# Using the same session, get an object repeatedly over a time period greater than the 1 hour token expiration limit.\n",
    "import time\n",
    "\n",
    "for i in range(1, 120):\n",
    "    now = datetime.datetime.now()\n",
    "    response = client.get_object(\n",
    "        Bucket=bucket,\n",
    "        Key=key)\n",
    "    print(\"You just accessed \" + response[\"ResponseMetadata\"][\"HTTPHeaders\"][\"content-length\"] + \" bytes of data in-region via the AWS S3 API at \")\n",
    "    print(now) \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d7f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
