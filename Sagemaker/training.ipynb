{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an image classification model using Sagemaker and HLS imagery from Earthdata Cloud (EDC).\n",
    "Using a set of training data defined [here](https://github.com/nasa-esdswg-ml/edc-notebooks/blob/main/Sagemaker/data-preparation.ipynb) we will train a model using SageMaker's 'image-classification' framework.\n",
    "\n",
    "Note: In order for this to work correctly with EDC we would need to grant read access to the AWS user associated with the 'sandbox' profile. That is not currently possible. In this notebook, you should copy the data to an S3 bucket your user has normal read access to using the technique outline [here](https://github.com/nasa-esdswg-ml/edc-notebooks/blob/main/EDC%20Data%20Access/s3-access.ipynb). This is one of the primary findings of our EDC+ML investigation and recommendations will be made to EOSDIS to make Sagemaker direct data access (ie. usage of EDC data without having to copy) possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import image_uris\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "\n",
    "training_image = image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, framework=\"image-classification\"\n",
    ")\n",
    "\n",
    "training_manifest_file_s3_location = \"<your training data manifest file here>\"\n",
    "validation_manifest_file_s3_location = \"<your validation data manifest file here>\"\n",
    "job_name_prefix = \"<yourimage classfication job name prefix here>\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "In order to train our model we need labelled data. The labelling is supplied by an [augmented manifest file](https://github.com/nasa-esdswg-ml/edc-notebooks/blob/main/Sagemaker/data-preparation.ipynb) located in an S3 bucket that you own. \n",
    "\n",
    "That file labels data resident in a bucket in the EDC (which you do not own). For example, a line in that file would look like this:\n",
    "\n",
    "`{\"source-ref\": \"s3://lp-prod-public/HLSL30.020/HLS.L30.T01FBF.2021104T213801.v2.0/HLS.L30.T01FBF.2021104T213801.v2.0.jpg\", \"class\": \"1\"}`\n",
    "\n",
    "Indicating that the browse image in `lp-prod-public` is a cloudy image.\n",
    "\n",
    "We supply a manifest file for both training and validation of the model.\n",
    "\n",
    "The 'training_params' variable contains the configuration we need to train the model for our cloudy/not cloudy use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this training, we will use 18 layers\n",
    "num_layers = \"18\"\n",
    "# we need to specify the input image shape for the training data\n",
    "image_shape = \"1000,1000\"\n",
    "# In our training data preparation notebook we used 100 traingin samples\n",
    "num_training_samples = \"100\"\n",
    "# specify the number of output classes. Our classes are 'source-ref' and 'class'\n",
    "num_classes = \"2\"\n",
    "# batch size for training\n",
    "mini_batch_size = \"50\"\n",
    "# number of epochs\n",
    "epochs = \"2\"\n",
    "# learning rate\n",
    "learning_rate = \"0.01\"\n",
    "\n",
    "job_name = job_name_prefix + \"-\" + time.strftime(\"-%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "training_params = {\n",
    "    \"AlgorithmSpecification\": {\"TrainingImage\": training_image, \"TrainingInputMode\": \"Pipe\"},\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\"S3OutputPath\": \"s3://{}/{}/output\".format(bucket, job_name_prefix)},\n",
    "    \"ResourceConfig\": {\"InstanceCount\": 1, \"InstanceType\": \"ml.p3.2xlarge\", \"VolumeSizeInGB\": 50},\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"num_layers\": str(num_layers),\n",
    "        \"num_training_samples\": str(num_training_samples),\n",
    "        \"num_classes\": str(num_classes),\n",
    "        \"mini_batch_size\": str(mini_batch_size),\n",
    "        \"epochs\": str(epochs),\n",
    "        \"learning_rate\": str(learning_rate)\n",
    "    },\n",
    "    \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 360000},\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"AttributeNames\": [\"source-ref\", \"class\"],\n",
    "                    \"S3DataType\": \"AugmentedManifestFile\",\n",
    "                    \"S3Uri\": training_manifest_file_s3_location,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"RecordWrapperType\": \"RecordIO\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"AttributeNames\": [\"source-ref\", \"class\"],\n",
    "                    \"S3DataType\": \"AugmentedManifestFile\",\n",
    "                    \"S3Uri\": validation_manifest_file_s3_location,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"RecordWrapperType\": \"RecordIO\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "    \n",
    "print(\"Training job name: {}\".format(job_name))\n",
    "print(\n",
    "    \"\\nInput Data Location: {}\".format(\n",
    "        training_params\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our AWS session and obtain a SageMaker service handle. We then create a training job and wait for that job to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Amazon SageMaker training job\n",
    "session = boto3.Session(profile_name='sandbox')\n",
    "sagemaker = session.client(service_name=\"sagemaker\")\n",
    "sagemaker.create_training_job(**training_params)\n",
    "\n",
    "# confirm that the training job has started\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\n",
    "print(\"Training job current status: {}\".format(status))\n",
    "\n",
    "try:\n",
    "    # wait for the job to finish and report the ending status\n",
    "    sagemaker.get_waiter(\"training_job_completed_or_stopped\").wait(TrainingJobName=job_name)\n",
    "    training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "    status = training_info[\"TrainingJobStatus\"]\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "except:\n",
    "    print(\"Training failed to start\")\n",
    "    # if exception is raised, that means it has failed\n",
    "    message = sagemaker.describe_training_job(TrainingJobName=job_name)[\"FailureReason\"]\n",
    "    print(\"Training failed with the following error: {}\".format(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "status = training_info[\"TrainingJobStatus\"]\n",
    "print(\"Training job ended with status: \" + status)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model\n",
    "Upone completionof the training job, we can create a model. Once created, we are given a model ARN that we can use to create an inference endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"DEMO-full-image-classification-model\" + time.strftime(\n",
    "    \"-%Y-%m-%d-%H-%M-%S\", time.gmtime()\n",
    ")\n",
    "print(model_name)\n",
    "info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(model_data)\n",
    "\n",
    "hosting_image = image_uris.retrieve(\n",
    "    region=session.region_name, framework=\"image-classification\"\n",
    ")\n",
    "\n",
    "primary_container = {\n",
    "    \"Image\": hosting_image,\n",
    "    \"ModelDataUrl\": model_data,\n",
    "}\n",
    "\n",
    "create_model_response = sagemaker.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, PrimaryContainer=primary_container\n",
    ")\n",
    "\n",
    "print(\"Model ARN: \" + create_model_response[\"ModelArn\"])\n",
    "print(\"Model Name: \" + model_name)\n",
    "print(\"Training job prefix: \" + job_name_prefix)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (v3.10.5:f377153967, Jun  6 2022, 12:36:10) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
